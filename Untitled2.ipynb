{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram\n",
    "from matplotlib import pyplot as plt\n",
    "import speech_recognition as sr\n",
    "from wit import Wit\n",
    "from sklearn import preprocessing, model_selection\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv1D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createPaddedSpectrogram(audio):\n",
    "    f, t ,Sxx = spectrogram(audio[1], fs=44100)\n",
    "    length = Sxx.shape[1] if Sxx.shape[1] < 450 else 450\n",
    "    f_cut = f[f<2000.0]\n",
    "    Sxx = Sxx[:12, :]\n",
    "    Sxx_padded = np.zeros((12,450))\n",
    "    Sxx_padded[:12, :length] = Sxx[:12,:length]\n",
    "#     plt.figure(figsize=(18,5))\n",
    "#     plt.pcolormesh(t,f_cut, Sxx)\n",
    "#     plt.show()\n",
    "    return Sxx_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sayKeyword(keyword, output_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    mic = sr.Microphone()\n",
    "    wit_api = Wit('VE3COSMD3FBL4DBGPHNZJICM7ZCUJ7J5')\n",
    "    with mic as source:\n",
    "        print(\"Adjusting mic...\")\n",
    "        recognizer.adjust_for_ambient_noise(mic, 3)\n",
    "        print(\"Say water\")\n",
    "        audio = recognizer.listen(mic, 2, 2.5)\n",
    "        print(\"Detecting what you said...\")\n",
    "        response = wit_api.speech(audio.get_wav_data(), None, {'Content-Type': 'audio/wav'})\n",
    "        if response['_text'] != keyword:\n",
    "            i=i-1;\n",
    "            print('Please speak more clearly')\n",
    "        else:\n",
    "            file = open(output_file,'wb')\n",
    "            file.write(audio.get_wav_data())\n",
    "            file.close()\n",
    "            print(\"All good\")\n",
    "    \n",
    "    audio_data = wavfile.read(output_file)\n",
    "    return audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#adding water pronunciation spectrograms from various speakers\n",
    "Sxx_array = np.empty((110,12,450))\n",
    "\n",
    "for i in range (1,111):\n",
    "    filename = \"data/pronunciation_en_water({0}).wav\".format(i)\n",
    "    audio = wavfile.read(filename)  \n",
    "    Sxx_padded = createPaddedSpectrogram(audio)\n",
    "    Sxx_array[i-1] = Sxx_padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#adding personal spectrogram to the array\n",
    "recording = False\n",
    "\n",
    "if recording == True:\n",
    "    for i in range(0,6):\n",
    "        audio_data = sayKeyword('water', 'data/personal_{0}.wav'.format(i))\n",
    "        Sxx_padded = createPaddedSpectrogram(audio_data)\n",
    "        Sxx_array = np.append(Sxx_array, Sxx_padded)\n",
    "else:\n",
    "    for i in range(0,6):\n",
    "        audio_data = wavfile.read('data/personal_{0}.wav'.format(i))\n",
    "        Sxx_padded = createPaddedSpectrogram(audio_data)\n",
    "        Sxx_array = np.append(Sxx_array, Sxx_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sxx_array = Sxx_array.reshape(116, 12, 450)\n",
    "Y_array = np.zeros(116)\n",
    "Y_array[110:] = 1 \n",
    "# Y_array = Y_array.reshape((116,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = model_selection.train_test_split(Sxx_array,Y_array, test_size= 0.8, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23 samples, validate on 93 samples\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0982 - acc: 0.9130 - val_loss: 0.0533 - val_acc: 0.9570\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0937 - acc: 0.9130 - val_loss: 0.0519 - val_acc: 0.9570\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0940 - acc: 0.9130 - val_loss: 0.0481 - val_acc: 0.9570\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0888 - acc: 0.9130 - val_loss: 0.0480 - val_acc: 0.9570\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0825 - acc: 0.9130 - val_loss: 0.0467 - val_acc: 0.9570\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1009 - acc: 0.9130 - val_loss: 0.0546 - val_acc: 0.9570\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0768 - acc: 0.9130 - val_loss: 0.0496 - val_acc: 0.9570\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0988 - acc: 0.9130 - val_loss: 0.0491 - val_acc: 0.9570\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0827 - acc: 0.9130 - val_loss: 0.0524 - val_acc: 0.9570\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0882 - acc: 0.9130 - val_loss: 0.0530 - val_acc: 0.9570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b48953b00>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(12, 450,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('softmax'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', metrics=['accuracy'], optimizer='adam')\n",
    "model.fit(xtrain, ytrain, batch_size=32, epochs=10, validation_data=(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting mic...\n",
      "Say water\n",
      "Detecting what you said...\n",
      "All good\n"
     ]
    }
   ],
   "source": [
    "#now trying recording test audio\n",
    "test_data = sayKeyword('water', 'data/testAudio.wav')\n",
    "# test_data = wavfile.read('data/testAudio.wav')\n",
    "test_padded = createPaddedSpectrogram(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03484063]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_padded.reshape(1,12,450))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
